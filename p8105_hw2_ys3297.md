HW2
================
Yi Sun

Solution to HW2.

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Define a path to the Mr. Trash Wheel dataset.

``` r
path_trash_wheel = "./Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

Read and clean the Mr. Trash Wheel dataset

``` r
trashwheel_df = 
  read_excel(
    path = path_trash_wheel, 
    sheet = "Mr. Trash Wheel", 
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read and clean the 2017 and 2018 precipitation datasets.

``` r
precipitation_2017 = 
  read_excel(
    path = path_trash_wheel, 
    sheet = "2017 Precipitation", 
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)

precipitation_2018 = 
  read_excel(
    path = path_trash_wheel, 
    sheet = "2018 Precipitation", 
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)
```

Next, combine the 2017 and 2018 precipitation datasets with the helper
dataframe `month_df`.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precipitation_combine = 
  bind_rows(precipitation_2017, precipitation_2018)

precipitation_combine = 
  left_join(precipitation_combine, month_df, by = "month")
```

There are 344 rows in the final Mr. Trash Wheel dataset and 24 rows in
the combined precipitation dataset of 2017 and 2018.

The final Mr. Trash Wheel dataset contains information on year, month,
date, weight and volume of trash collected, and quantity of some
specific kinds of trash.

The combined precipitation dataset of 2017 and 2018 contains
precipitation data by month for 2017 and 2018.

  - The total precipitation in 2018 was 70.33 inches.
  - The median number of sports balls in a dumpster in 2017 was 8.

## Problem 2

Define a path to the NYC subway transit dataset.

``` r
path_NYC_subway = "./NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
```

Read and clean the NYC subway transit dataset, only retaining variables
needed.

``` r
NYC_subway_df = 
  read_csv(path_NYC_subway) %>% 
  janitor::clean_names() %>% 
  select(line:entrance_type, entry, vending, ada) %>% 
  mutate(entry = as.logical(
    ifelse(entry == "YES", 1, 0)
  ))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

The resulting dataset of NYC subway transit `NYC_subway_df` only keeps
variables like line, station name, latitude and longitude of station,
routes served, entry, vending, entrance type, and ADA compliance.

The variable `entry` is converted to a logical variable.

There are 1868 rows and 19 columns in the resulting dataset of NYC
subway transit `NYC_subway_df`.

The data in `NYC_subway_df` are still not tidy. There are still
redundant columns for routes served, or the route numbers that should be
values are still in the variable names.

  - There are 465 distinct stations.
  - There are 84 ADA compliant stations.
  - 37.704918% of station entrances / exits without vending allow
    entrance.

Reformat `NYC_subway_df` to make route number and route name distinct
variables.

``` r
NYC_subway_df = 
  NYC_subway_df %>% 
  mutate_at(vars(route8:route11), as.character) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    names_prefix = "route",
    values_to = "route_name"
  ) %>% 
  drop_na(route_name)
```

  - 60 distinct stations serve the A train.
  - Of the stations that serve the A train, 17 distinct stations are ADA
    compliant.

## Problem 3

Define a path to the pols-month dataset.

``` r
path_to_pols_month = "./data_538/pols-month.csv"
```

Read and clean the pols-month dataset.

``` r
pols_month_df = 
  read_csv(path_to_pols_month) %>% 
  janitor::clean_names() %>% 
  separate(mon, c("year", "month", "day"), "-", convert = TRUE) %>% 
  mutate(month = month.name[month]) %>% 
  mutate(president = ifelse(prez_gop == 1, "gop", "dem")) %>% 
  select(-c(prez_gop, prez_dem, day))
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Define a path to the snp dataset.

``` r
path_to_snp = "./data_538/snp.csv"
```

Read and clean the snp dataset.

``` r
snp_df = 
  read_csv(path_to_snp) %>% 
  janitor::clean_names() %>% 
  separate(date, c("month", "day", "year"), "/", convert = TRUE) %>% 
  arrange(year, month) %>% 
  mutate(month = month.name[month]) %>% 
  relocate(year, month) %>% 
  select(-day)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Define a path to the unemployment dataset.

``` r
path_to_unemployment = "./data_538/unemployment.csv"
```

Read, clean, and tidy the unemployment dataset. Use the helper dataframe
`month_abb_df` to convert month abbreviations to month names.

``` r
month_abb_df = 
  tibble(
    month = month.name,
    month_abb = month.abb
  )

unemployment_df = 
  read_csv(path_to_unemployment) %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month_abb",
    values_to = "unemployment_percent"
  ) %>% 
  left_join(month_abb_df, by = "month_abb") %>% 
  janitor::clean_names() %>% 
  relocate(year, month) %>% 
  select(-month_abb) %>% 
  drop_na(unemployment_percent)
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Merge `snp_df` into `pols_month_df`, and merge `unemployment_df` into
the result.

``` r
combine_df = 
  left_join(pols_month_df, snp_df, by = c("year", "month")) %>% 
  left_join(unemployment_df, by = c("year", "month"))
```

`pols_month_df` reads from pols-month.csv in the FiveThirtyEight data
and contains the numbers of national politicians (governors, senators,
and representatives) who are democratic or republican and the political
party of the president by month from January 1947 to June 2015.

`snp_df` reads from snp.csv in the FiveThirtyEight data and contains the
closing value of the S\&P stock index on the associated date from
January 1950 to July 2015 (one date for each month).

`unemployment_df` reads from unemployment.csv in the FiveThirtyEight
data and contains the percentage of unemployment in any given month from
January 1948 to June 2015.

In the resulting dataset `combine_df`, there are 822 rows and 11
columns. This dataset contains information from 1947 to 2015. Variables
in this dataset include `year`, `month`, `president` indicating the
political party of the president at the time, `close` indicating the
closing value of the S\&P stock index at the time, and
`unemployment_percent` indicating the percentage of unemployment at the
time.
