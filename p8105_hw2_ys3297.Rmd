---
title: "HW2"
author: Yi Sun
output: github_document
---

Solution to HW2.

```{r setup}
library(tidyverse)
library(readxl)
```

## Problem 1

Define a path to the Mr. Trash Wheel dataset.

```{r}
path_trash_wheel = "./Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```


Read and clean the Mr. Trash Wheel dataset

```{r}
trashwheel_df = 
  read_excel(
    path = path_trash_wheel, 
    sheet = "Mr. Trash Wheel", 
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read and clean the 2017 and 2018 precipitation datasets.

```{r}
precipitation_2017 = 
  read_excel(
    path = path_trash_wheel, 
    sheet = "2017 Precipitation", 
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)

precipitation_2018 = 
  read_excel(
    path = path_trash_wheel, 
    sheet = "2018 Precipitation", 
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)
```

Next, combine the 2017 and 2018 precipitation datasets with the helper dataframe `month_df`.

```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precipitation_combine = 
  bind_rows(precipitation_2017, precipitation_2018)

precipitation_combine = 
  left_join(precipitation_combine, month_df, by = "month")
```

There are `r nrow(trashwheel_df)` rows in the final Mr. Trash Wheel dataset and `r nrow(precipitation_combine)` rows in the combined precipitation dataset of 2017 and 2018. 

The final Mr. Trash Wheel dataset contains information on year, month, date, weight and volume of trash collected, and quantity of some specific kinds of trash. 

The combined precipitation dataset of 2017 and 2018 contains precipitation data by month for 2017 and 2018. 

* The total precipitation in 2018 was `r precipitation_combine %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.
* The median number of sports balls in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`.

## Problem 2

Define a path to the NYC subway transit dataset.

```{r}
path_NYC_subway = "./NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
```

Read and clean the NYC subway transit dataset, only retaining variables needed.

```{r}
NYC_subway_df = 
  read_csv(path_NYC_subway) %>% 
  janitor::clean_names() %>% 
  select(line:entrance_type, entry, vending, ada) %>% 
  mutate(entry = as.logical(
    ifelse(entry == "YES", 1, 0)
  ))
```

The resulting dataset of NYC subway transit `NYC_subway_df` only keeps variables like line, station name, latitude and longitude of station, routes served, entry, vending, entrance type, and ADA compliance.

The variable `entry` is converted to a logical variable.

There are `r nrow(NYC_subway_df)` rows and `r ncol(NYC_subway_df)` columns in the resulting dataset of NYC subway transit `NYC_subway_df`.

The data in `NYC_subway_df` are still not tidy. There are still redundant columns for routes served, or the route numbers that should be values are still in the variable names.

* There are `r NYC_subway_df %>% distinct(line, station_name) %>% nrow()` distinct stations.
* There are `r NYC_subway_df %>% filter(ada == TRUE) %>% distinct(line, station_name) %>% nrow()` ADA compliant stations.
* `r nrow(filter(NYC_subway_df, entry == TRUE & vending == "NO"))/nrow(filter(NYC_subway_df, vending == "NO"))*100`% of station entrances / exits without vending allow entrance.

Reformat `NYC_subway_df` to make route number and route name distinct variables.

```{r}
NYC_subway_df = 
  NYC_subway_df %>% 
  mutate_at(vars(route8:route11), as.character) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    names_prefix = "route",
    values_to = "route_name"
  ) %>% 
  drop_na(route_name)
```

* `r NYC_subway_df %>% filter(route_name == "A") %>% distinct(line, station_name) %>% nrow()` distinct stations serve the A train.
* Of the stations that serve the A train, `r NYC_subway_df %>% filter(route_name == "A" & ada == TRUE) %>% distinct(line, station_name) %>% nrow()` distinct stations are ADA compliant.

## Problem 3

Define a path to the pols-month dataset.

```{r}
path_to_pols_month = "./data_538/pols-month.csv"
```

Read and clean the pols-month dataset.

```{r}
pols_month_df = 
  read_csv(path_to_pols_month) %>% 
  janitor::clean_names() %>% 
  separate(mon, c("year", "month", "day"), "-", convert = TRUE) %>% 
  mutate(month = month.name[month]) %>% 
  mutate(president = ifelse(prez_gop == 1, "gop", "dem")) %>% 
  select(-c(prez_gop, prez_dem, day))
```

Define a path to the snp dataset.

```{r}
path_to_snp = "./data_538/snp.csv"
```

Read and clean the snp dataset.

```{r}
snp_df = 
  read_csv(path_to_snp) %>% 
  janitor::clean_names() %>% 
  separate(date, c("month", "day", "year"), "/", convert = TRUE) %>% 
  arrange(year, month) %>% 
  mutate(month = month.name[month]) %>% 
  relocate(year, month) %>% 
  select(-day)
```

Define a path to the unemployment dataset.

```{r}
path_to_unemployment = "./data_538/unemployment.csv"
```

Read, clean, and tidy the unemployment dataset. Use the helper dataframe `month_abb_df` to convert month abbreviations to month names.

```{r}
month_abb_df = 
  tibble(
    month = month.name,
    month_abb = month.abb
  )

unemployment_df = 
  read_csv(path_to_unemployment) %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month_abb",
    values_to = "unemployment_percent"
  ) %>% 
  left_join(month_abb_df, by = "month_abb") %>% 
  janitor::clean_names() %>% 
  relocate(year, month) %>% 
  select(-month_abb) %>% 
  drop_na(unemployment_percent)
```

Merge `snp_df` into `pols_month_df`, and merge `unemployment_df` into the result.

```{r}
combine_df = 
  left_join(pols_month_df, snp_df, by = c("year", "month")) %>% 
  left_join(unemployment_df, by = c("year", "month"))
```

`pols_month_df` reads from pols-month.csv in the FiveThirtyEight data and contains the numbers of national politicians (governors, senators, and representatives) who are democratic or republican and the political party of the president by month from January 1947 to June 2015.

`snp_df` reads from snp.csv in the FiveThirtyEight data and contains the closing value of the S&P stock index on the associated date from January 1950 to July 2015 (one date for each month).

`unemployment_df` reads from unemployment.csv in the FiveThirtyEight data and contains the percentage of unemployment in any given month from January 1948 to June 2015.

In the resulting dataset `combine_df`, there are `r nrow(combine_df)` rows and `r ncol(combine_df)` columns. This dataset contains information from `r combine_df %>% pull(year) %>% min()` to `r combine_df %>% pull(year) %>% max()`. Variables in this dataset include `year`, `month`, `president` indicating the political party of the president at the time, `close` indicating the closing value of the S&P stock index at the time, and `unemployment_percent` indicating the percentage of unemployment at the time.
